<html>
<head>
    <title> Savvas Petridis </title>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
     <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
    <link rel="stylesheet" href="./main.css">

    <style>
        .section{
            padding-top: 20px;
        }
        .organizer{
            padding-top: 10px;
        }

        .columbia-background1{
          background-color: #edf3f6; /*#C4D8E2;*/ 
        }
        .padding-div{
          padding-top: 0px;
          padding-bottom: 10px
        }

    </style>

</head>
<body>

 <nav class="navbar navbar-expand-lg navbar-fixed-top navbar-light bg-light">
  <div class='container'>
  <a class="navbar-brand" href="#"> <h2> <font color="#0066ff"> Savvas Petridis </font> </h2> </a>
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item">
        <a class="nav-link" href="#projects"> Projects </a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="#publications"> Publications </a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="./savvas_resume_2021.pdf"> CV (2021) </a>
      </li>
    </ul>
  </div>
  </div>
</nav>

<div class="columbia-background1" style="padding-top: 50px">
  <div class="padding-div">  
    <div class='container'>       
      <div class="row"> 
        <div class="col-md-3 text-center" >
          <img src="./images/me_small.jpeg" alt="Savvas Petridis" class="protrait"><br><br>
          <!-- <div class="center_div"> -->
          <div>
          <a href="https://scholar.google.com/citations?user=fEPjVfIAAAAJ&hl=en&oi=ao" class="link_button">Google Scholar</a>
          ·
          <a href="https://www.semanticscholar.org/author/21622968"  class="link_button">Semantic Scholar</a>
          ·
          <a href="./savvas_resume_2021.pdf" class="link_button" >CV (2021)</a>
          ·
          <a href="https://www.linkedin.com/in/savvaspetridis/"  class="link_button">LinkedIn</a>
          </div>
          <br>
        </div>         
        <div class="col-md-6"> 
          <h4> Hi, I'm Savvas. </h4>
          
          <p><b>I am a postdoctoral researcher at</b> <a href="https://pair.withgoogle.com/">Google PAIR</a>. I research how to make large language models usable for everyone, from investigative journalists to designers. </p>

          I received my PhD in computer science (specialized in HCI, AI, and Sensemaking) from <a href="https://www.columbia.edu/">Columbia University</a>, where I was lucky to be advised by <a href="https://www.cs.columbia.edu/~chilton/">Prof. Lydia B. Chilton</a>. I was also fortunate to have research internships at <a href="https://research.atspotify.com/">Spotify</a>, <a href="https://research.adobe.com/">Adobe</a>, and <a href="https://research.ibm.com/">IBM</a>.  
          </p>

          <p>
          Feel free to reach out to me at: <b> savvas@cs.columbia.edu </b> <br> </p>

          <!-- <p class="highlight_text"> <b> I'm on the job market! </b> I'm interested in both industry and academic research opportunities - happy to connect. </p> --> 

        </div>
        
      </div>
    </div>
  </div>
</div>  

<!-- <div class="container">
  <div id="news" class='section'>
  <h3> News </h3>
  </div>
</div> -->

<div class="container">
  <div id="projects" class='section'>
    <h3> Selected Projects </h3>
    <br>

        <div class="row"> 
      <div class="col-md-4 "> 
        <img src="./images/anglekindling_interface.png" class="project_picture">
      </div>
      <!-- <div class="col-md-6 col-sm-12"> -->
      <div class="col-md-6">
        <p class="paper_title"> AngleKindling: Supporting Journalistic Angle Ideation with Large Language Models  <small>[CHI 2023] </small> </p>
        <p>
        News media often leverage documents to find ideas for stories, while being critical of the frames and narratives present. Developing angles from a document such as a press release is a cognitively taxing process, in which journalists examine the implicit meaning of its claims. Informed by interviews with journalists, we developed AngleKindling, an interactive tool which employs the common sense reasoning of LLMs to help journalists explore angles for reporting on a press release. In a study with 12 professional journalists, we show that participants found AngleKindling signifcantly more helpful and less mentally demanding to use for brainstorming ideas, compared to a prior journalistic angle ideation tool. 
        </p>
        [<a target="_blank" href="./papers/anglekindling.pdf">pdf</a>]
        
      </div>
    </div>

    <hr>

    <div class="row"> 
      <div class="col-md-4 "> 
        <img src="./images/tp_2.png" class="project_picture">
      </div>
      <!-- <div class="col-md-6 col-sm-12"> -->
      <div class="col-md-6">
        <p class="paper_title"> TastePaths: Enabling Deeper Exploration and Understanding of Personal Preferences in Recommender Systems  <small>[IUI 2022] </small>  </p>
        <p>
        Recommender systems are ubiquitous and influence the information we consume daily by helping us navigate vast
catalogs of information like music databases. However, their linear approach of surfacing content in ranked lists limits
their ability to help us grow and understand our personal preferences. In this paper, we study how we can better support
users in exploring a novel space, specifically focusing on music genres. Informed by interviews with expert music
listeners, we developed TastePaths: an interactive web tool that helps users explore an overview of the genre-space via
a graph of connected artists. 
        </p>
        [<a target="_blank" href="./papers/tastepaths.pdf">pdf</a>]
        
      </div>
    </div>

    <hr>

    <div class="row"> 
      <div class="col-md-4"> 
        <img src="./images/symbol_finder_image.png" class="project_picture3">
      </div>
      <div class="col-md-6"> 
        <!-- <h5> SymbolFinder: Brainstorming diverse symbols using local semantic networks </h5> -->
        <p class="paper_title"> SymbolFinder: Brainstorming Diverse Symbols Using Local Semantic Networks  <small>[UIST 2021] </small> </p>
        <p>
        Visual symbols are the building blocks for visual communication. They convey abstract concepts like <i> reform
</i> and <i> participation </i> with concrete objects like scaffolding and key. Student designers struggle to brainstorm
diverse symbols because they need to recall associations instead of recognizing them and they fixate on a few
associations instead of exploring different related contexts. We present SymbolFinder, an interactive tool for
finding visual symbols for abstract concepts. SymbolFinder molds symbol-finding into a recognition rather
than recall task by introducing the user to diverse clusters associated with the concept. Users can dive into
these clusters to find related, concrete objects that can symbolize the concept. 
        </p>
        [<a target="_blank" href="./papers/symbolfinder.pdf">pdf</a>]
        [<a target="_blank" href="https://www.youtube.com/watch?v=5qO6XF_nwCg">talk</a>]
        <!-- [<a target="_blank" href="https://columbia-computational-design-lab.github.io/symbol_finder_web/">project page</a>] --> 
        <!-- https://www.youtube.com/watch?v=5qO6XF_nwCg --> 
      </div>
    </div>

    <!-- 
    <hr>
    <div class="row"> 
      <div class="col-md-4"> 
        <img src="./images/vb_system_outline.png" class="project_picture">
      </div>
      <div class="col-md-6"> 
        <p class="paper_title"> VisiBlends: A Flexible Workflow for Visual Blends  <small>[CHI 2019] </small> </p>
        <p>
        Visual blends are an advanced graphic design technique to draw attention to a message. They combine two objects in a way that is novel and useful in conveying a message symbolically. VisiBlends is a flexible workflow for creating visual blends that follows the iterative design process. We introduce a design pattern for blending symbols based on principles of human visual object recognition. Our workflow decomposes the process into both computational techniques and human microtasks. It allows users to collaboratively generate visual blends with steps involving brainstorming, synthesis, and iteration. 
        </p>
        [<a target="_blank" href="./papers/visiblends.pdf">paper</a>]
      </div>
    </div>

    <hr>
    <div class="row"> 
      <div class="col-md-4"> 
        <img src="./images/top2_bot2_3.png" class="project_picture2">
      </div>
      <div class="col-md-6"> 
        <p class="paper_title"> Human Errors in Interpreting Visual Metaphor  <small>[C&C 2019] </small> </p>
        <p> How do people interpret visual metaphors? What errors do they make? How can we learn from these errors to better visual communication and automatic machine understanding of advertisements? In this work, we provide evidence for four distinct types of errors people make in interpreting visual metaphors. We also show that people’s ability to interpret a visual message is not simply a function of image content but also of message familiarity. We discuss how our findings can be applied toward bettering visual communication. </p>
        [<a target="_blank" href="./papers/human_errors.pdf">paper</a>]
      </div>
    </div>

    <hr>

    <div class="row"> 
      <div class="col-md-4"> 
        <img src="./images/liar_dataset_excerpt.png" class="project_picture">
      </div>
      <div class="col-md-6"> 
        <p class="paper_title"> Where is your Evidence: Improving Fact-checking by Justification Modeling  <small>[FEVER @ EMNLP 2018] </small> </p>
        <p> Fact-checking is a journalistic practice that compares a claim made publicly against trusted sources of facts. We extend the LIAR dataset by automatically extracting the justification from the fact-checking article used by humans to label a given claim. We show that modeling the extracted justification in conjunction with the claim (and metadata) provides a significant improvement regardless of the machine learning model used.</p>
        [<a target="_blank" href="./papers/evidence_paper.pdf">paper</a>]
      </div>
    </div>

    <hr>

    <div class="row"> 
      <div class="col-md-4"> 
        <img src="./images/amuse_demo.png" class="project_picture">
      </div>
      <div class="col-md-7"> 
        <p class="paper_title"> AMuSe: Large-scale WiFi video distribution-experimentation on the ORBIT testbed  <small> [IEEE LCN 2015, INFOCOM 2016] </small> </p>
        <p> AMuSe is a scalable system for WiFi multicast video delivery. The system includes a scheme for dynamic selection of a subset of the receivers as feedback nodes and a rate adaptation algorithm MuDRA that maximizes the channel utilization while meeting QoS requirements. We implemented AMuSe in the ORBIT testbed and evaluated its performance with 150-200 nodes. We present a dynamic web-based application that demonstrates the operation of AMuSe based on traces collected on the testbed in several experiments. The application allows us to compare the performance of AMuSe with other multicast schemes and evaluate the performance of video delivery. 

        <b> This demo was presented at the NYC Media Lab Summit and <a target="_blank" href="https://wimnet.ee.columbia.edu/second-place-prize-for-a-demo-in-the-media-lab-summit/"> won second place! </a> </b></p>
        [<a target="_blank" href="https://wimnet.ee.columbia.edu/wp-content/uploads/2016/03/infocomdemo.pdf">paper 1</a>]
        [<a target="_blank" href="https://wimnet.ee.columbia.edu/wp-content/uploads/2013/03/LCN_Demo.pdf">paper 2</a>]
      </div>
    </div>
  -->
  


  </div>
</div>
  

<br>


<div class="columbia-background1"> 
  <div class="container">
    <div id="publications" class='section'>
      <div class="row">        
          <div class="col-md-12">   
            <h3>Publications</h3>

            <i><a href="./papers/promptinfuser.pdf"><strong>PromptInfuser: Bringing User Interface Mock-ups to Life with Large Language Models</strong></a></i><br>
            <b> Savvas Petridis</b>, <a href="https://research.google/people/107786/">Michael Terry</a>, <a href="https://sites.google.com/view/carriecai/home?pli=1">Carrie J. Cai</a>. <br>
            CHI 2023 Late Breaking Work, ACM Conference on Human Factors in Computing Systems.
            <br> <br>

            <i><a href="./papers/anglekindling.pdf"><strong>AngleKindling: Supporting Journalistic Angle Ideation with Large Language Models</strong></a></i><br>
            <b> Savvas Petridis</b>, <a href="https://www.nickdiakopoulos.com/">Nicholas Diakopoulos</a>, <a href="https://crowston.syr.edu/">Kevin Crowston</a>, <a href="https://journalism.columbia.edu/faculty/mark-hansen"> Mark Hansen</a>, <a href="https://newhouse.syr.edu/people/keren-henderson"> Keren Henderson</a>, <a href="https://newhouse.syr.edu/people/stan-jastrzebski"> Stan Jastrzebski</a>, <a href="https://www.stevens.edu/profile/jnickers"> Jeffrey V. Nickerson</a>, <a href="https://www.cs.columbia.edu/~chilton/chilton.html"> Lydia B. Chilton</a>. <br>
            CHI 2023, ACM Conference on Human Factors in Computing Systems.
            <br> <br>

            <i><a href="./papers/popblends.pdf"><strong>PopBlends: Strategies for Conceptual Blending with Large Language Models</strong></a></i><br>
            <a href="https://sitong-wang.github.io/">Sitong Wang</a>, <b> Savvas Petridis</b>, <a href="https://terrykwon.com/">Taeahn Kwon</a>, <a href="https://www.cse.ust.hk/~mxj//">Xiaojuan Ma</a>, <a href="https://www.cs.columbia.edu/~chilton/chilton.html"> Lydia B. Chilton</a>. <br>
            CHI 2023, ACM Conference on Human Factors in Computing Systems.
            <br> <br>


            <i><a href="./papers/tastepaths.pdf"><strong>TastePaths: Enabling Deeper Exploration and Understanding of Personal Preferences in Recommender Systems</strong></a></i><br>
            <b> Savvas Petridis</b>, <a href="https://nediyana.github.io/">Nediyana Daskalova</a>, <a href="http://sarahmennicken.com/">Sarah Mennicken</a>, <a href="http://samfway.com/"> Samuel F. Way</a>, <a href="https://musicmachinery.com/"> Paul Lamere</a>, <a href="https://www.jennthom.com/">Jennifer Thom</a>. <br>
            IUI 2022, ACM Conference on Intelligent User Interfaces.
            <br> <br>

            <i><a href="./papers/symbolfinder.pdf"> <strong> SymbolFinder: Brainstorming Diverse Symbols Using Local Semantic Networks </strong> </a></i><br>
            <b> Savvas Petridis</b>, <a href="https://hishin.github.io/"> Hijung Valentina Shin</a>, <a href="https://www.cs.columbia.edu/~chilton/chilton.html"> Lydia B. Chilton</a>.<br>
            UIST 2021, ACM Symposium on User Interface Software and Technology.
            <br> <br>

            <i><a href="./papers/human_errors.pdf"><strong>Human Errors in Interpreting Visual Metaphor </strong></a></i><br>
            <b> Savvas Petridis</b> and <a href="https://www.cs.columbia.edu/~chilton/chilton.html"> Lydia B. Chilton</a>.<br>
            C&C 2019, ACM Conference on Creativity and Cognition.
            <br> <br>

            <i><a href="./papers/visiblends.pdf"><strong>VisiBlends: A Flexible Workflow for Visual Blends</strong></a></i><br>
            <a href="https://www.cs.columbia.edu/~chilton/chilton.html"> Lydia B. Chilton</a>, <b> Savvas Petridis</b>, <a href="http://graphics.stanford.edu/~maneesh/"> Maneesh Agrawala</a>.<br>
            CHI 2019, ACM Conference on Human Factors in Computing Systems.
            <br> <br>
            
            <i><a href="./papers/evidence_paper.pdf"> <strong> Where is your Evidence: Improving Fact-checking by Justification </strong></a></i><br>
            <a href="https://www.cs.columbia.edu/~tariq/"> Tariq Alhindi</a>, <b> Savvas Petridis</b>,  <a href="http://www.cs.columbia.edu/~smara/"> Smaranda Muresan</a>. <br>
            FEVER (Fact Extraction and Verification) Workshop at EMNLP 2018.
            <br> <br>

            <i><a href="http://wimnet.ee.columbia.edu/wp-content/uploads/2016/03/infocomdemo.pdf"><strong> AMuSe: Large-scale WiFi video distribution - Experimentation on the ORBIT testbed </strong></a></i><br>
            Varun Gupta, Raphael Norwitz, <b>Savvas Petridis</b>, Craig Gutterman, Gil Zussman, Yigal Bejerano.<br>
            Demo description in Proc. IEEE INFOCOM'16, 2016.
            <br> <br>

            <i><a href="http://wimnet.ee.columbia.edu/wp-content/uploads/2013/03/LCN_Demo.pdf"> <strong>WiFi multicast to very large groups - experimentation on the ORBIT testbed </strong> </a></i><br>
            Varun Gupta, Raphael Norwitz, <b>Savvas Petridis</b>, Craig Gutterman, <a href="https://wimnet.ee.columbia.edu/people/gil-zussman/"> Gil Zussman</a>, Yigal Bejerano.<br>
            Demo at IEEE LCN'15, 2015.
            <br> <br>


          </div>
      </div>
    </div>
  </div>
</div>





</body>

</html>
